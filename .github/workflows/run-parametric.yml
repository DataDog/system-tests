name: Parametric
on:
  workflow_call:
    inputs:
      library:
        description: "Library to test"
        required: true
        type: string
      binaries_artifact:
        description: "Artifact name containing the binaries to test"
        default: ''
        required: false
        type: string
      force_execute:
        description: "List of nodeid to force execute, separated by comma"
        required: false
        type: string
        default: ''
      ci_environment:
        description: "Which CI environment is running the tests, used for FPD"
        default: 'custom'
        required: false
        type: string
      job_count:
        description: "How many job should be spawned for the parametric test"
        default: 1
        required: false
        type: number
      job_matrix:
        # github action syntax is not very powerfull, it require a job to compute this.
        # => save on job, by asking the caller to compute this list
        description: "Job matrix, JSON array of number from 1 to job_count"
        default: '[1]'
        required: false
        type: string
      ref:
        description: "system-tests ref to run the tests on (can be any valid branch, tag or SHA in system-tests repo)"
        type: string
      force_execute_tests:
        description: "Array of tests to force-execute, separated by commas"
        default: ''
        required: false
        type: string
      _experimental_job_count:
        description: "DEPRECATED"
        default: 1
        required: false
        type: number
      _experimental_job_matrix:
        description: "DEPRECATED"
        default: '[1]'
        required: false
        type: string
      _experimental_runs_on:
        description: "Runner definition"
        default: '{ "group": "APM Larger Runners" }'
        required: false
        type: string
      artifact_retention_days:
        description: "Maximum retention of artifacts generated by upload-artifact action"
        default: 14
        required: false
        type: number
      unique_id:
        description: "Unique ID to append to the artifact name, useful for parallel runs"
        default: "1"
        required: false
        type: string
      push_to_test_optimization:
        description: "Push test result to DataDog Test Optimization"
        default: false
        required: false
        type: boolean

env:
  REGISTRY: ghcr.io
jobs:

  parametric:
    runs-on: ${{ fromJson( inputs._experimental_runs_on ) }}
    strategy:
      fail-fast: false
      matrix:
        job_instance: ${{ fromJson( inputs.job_matrix ) }}
    env:
      SYSTEM_TESTS_REPORT_ENVIRONMENT: ${{ inputs.ci_environment }}
      SYSTEM_TESTS_REPORT_RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
      SYSTEM_TESTS_FORCE_EXECUTE: ${{ inputs.force_execute }}
    steps:
      - name: Compute ref
        id: compute_ref
        run: |
          if [[ "${{ inputs.ref }}" != "" ]]; then
            echo "ref=${{ inputs.ref }}" >> $GITHUB_OUTPUT
          elif [[ "${{ github.repository }}" == "DataDog/system-tests" ]]; then
            echo "ref=" >> $GITHUB_OUTPUT
          else
            echo "ref=main" >> $GITHUB_OUTPUT
          fi
      - name: Checkout
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955 # v4.3.0
        with:
          repository: DataDog/system-tests
          ref: ${{ steps.compute_ref.outputs.ref }}
      - name: Install runner
        uses: ./.github/actions/install_runner
      - name: Get binaries artifact
        if : ${{ inputs.binaries_artifact != '' }}
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4.3.0
        with:
          name: ${{ inputs.binaries_artifact }}
          path: binaries/
      - name: Export github token to a file
        run: echo "${{ secrets.GITHUB_TOKEN }}" > "$RUNNER_TEMP/github_token.txt"
      - name: Run PARAMETRIC scenario
        run: |
          ./run.sh PARAMETRIC\
            -L ${{ inputs.library }}\
            --splits=${{ inputs.job_count }}\
            --group=${{ matrix.job_instance }} \
            --github-token-file="$RUNNER_TEMP/github_token.txt"
            ${{inputs.force_execute_tests != '' && format('-F {0}', join(fromJSON(inputs.force_execute_tests), ' -F ')) || ''}}
      - name: Remove secrets
        if: always()
        run: |
          TOKEN_FILE="$RUNNER_TEMP/github_token.txt"
          if [ -f "$TOKEN_FILE" ]; then
            echo "Removing token file at $TOKEN_FILE"
            rm -f "$TOKEN_FILE"
          else
            echo "Token file not found â€” nothing to clean up"
          fi
      - name: Compress logs
        id: compress_logs
        if: always()
        run: |
          if compgen -G "logs*/" > /dev/null; then
            # the script that pushes logs to FPD does not handles folder name collisions.
            # waiting for a proper fix, we add the job instance in the folder name
            mv logs_parametric logs_parametric_${{ matrix.job_instance }}
            tar -czvf artifact.tar.gz logs*/
          else
            echo "No logs*/ found; skipping tar."
          fi
      - name: Upload artifact
        if: always() && steps.compress_logs.outcome == 'success'
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: logs_parametric_${{ inputs.library}}_parametric_${{ inputs.ci_environment }}_${{ matrix.job_instance }}_${{ inputs.unique_id }}
          path: artifact.tar.gz
          retention-days: ${{ inputs.artifact_retention_days }}

      - name: Push results to Test Optimization
        if: always() && inputs.push_to_test_optimization
        uses: ./.github/actions/push_to_test_optim
        with:
          datadog_api_key: ${{ secrets.TEST_OPTIMIZATION_API_KEY }}
