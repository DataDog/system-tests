include:
  - remote: https://gitlab-templates.ddbuild.io/libdatadog/one-pipeline/ca/2fc0ca684c4322af76c172905af32c6c583303dcecb07dba05bac5f85b7606ae/single-step-instrumentation-tests.yml

stages:
  - configure
  - nodejs
  - java
  - dotnet
  - python
  - php
  - ruby
  - pipeline-status
  - system-tests-utils

variables:
    # Do not modify this - must be the repository name for Kubernetes gitlab runners to run
    KUBERNETES_SERVICE_ACCOUNT_OVERWRITE: system-tests #helm-charts
    TEST: 1

compute_pipeline:
  image: registry.ddbuild.io/ci/libdatadog-build/system-tests:57161036
  tags: ["arch:amd64"]
  stage: configure
  variables:
    CI_ENVIRONMENT: "prod"
  script:
    - |
      if [ -z "$SYSTEM_TESTS_SCENARIOS" ] && [ -z "$SYSTEM_TESTS_SCENARIOS_GROUPS" ]; then
        echo "‚ùå Both SYSTEM_TESTS_SCENARIOS and SYSTEM_TESTS_SCENARIOS_GROUPS are not defined.Computing changes..."
        ./build.sh -i runner
        source venv/bin/activate
        ./run.sh MOCK_THE_TEST --collect-only --scenario-report
        git clone https://github.com/DataDog/system-tests.git original
        git fetch --all  # Ensure all branches are available
        git branch --track $CI_COMMIT_REF_NAME origin/$CI_COMMIT_REF_NAME || true  # Track branch if not tracked
        git checkout $CI_COMMIT_REF_NAME  # Ensure the branch is checked out
        BASE_COMMIT=$(git merge-base origin/main $CI_COMMIT_REF_NAME)  # Get the base commit
        echo "Branch was created from commit--> $BASE_COMMIT"
        git diff --name-only $BASE_COMMIT $CI_COMMIT_SHA  >> modified_files.txt # List modified files
        cat modified_files.txt
        python utils/scripts/compute_impacted_scenario.py >> impacted_scenarios.txt
        cat impacted_scenarios.txt
        source impacted_scenarios.txt
      else
          echo "‚úÖ SYSTEM_TESTS_SCENARIOS OR SYSTEM_TESTS_SCENARIOS_GROUPS are set."
          export scenarios=$SYSTEM_TESTS_SCENARIOS
          export scenarios_groups=$SYSTEM_TESTS_SCENARIOS_GROUPS
          cd /system-tests
          git pull
          if [ -n "$SYSTEM_TESTS_REF" ]; then
            git checkout $SYSTEM_TESTS_REF
          else
            echo "‚ö†Ô∏è  SYSTEM_TESTS_REF variable is not set, skipping git checkout"
          fi
          ./build.sh -i runner
          source venv/bin/activate
      fi
    - python utils/scripts/compute-workflow-parameters.py nodejs -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - python utils/scripts/compute-workflow-parameters.py java -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - python utils/scripts/compute-workflow-parameters.py dotnet -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - python utils/scripts/compute-workflow-parameters.py python -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - python utils/scripts/compute-workflow-parameters.py php -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - python utils/scripts/compute-workflow-parameters.py ruby -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - |
      if [ -n "$SYSTEM_TESTS_SCENARIOS" ] || [ -n "$SYSTEM_TESTS_SCENARIOS_GROUPS" ]; then
        cp *.yml "$CI_PROJECT_DIR"
      fi
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'
  artifacts:
    paths:
      - nodejs_ssi_gitlab_pipeline.yml
      - java_ssi_gitlab_pipeline.yml
      - dotnet_ssi_gitlab_pipeline.yml
      - python_ssi_gitlab_pipeline.yml
      - php_ssi_gitlab_pipeline.yml
      - ruby_ssi_gitlab_pipeline.yml

nodejs_ssi_pipeline:
  stage: nodejs
  needs: ["compute_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: nodejs_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

java_ssi_pipeline:
  stage: java
  needs: ["compute_pipeline", "nodejs_ssi_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: java_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

dotnet_ssi_pipeline:
  stage: dotnet
  needs: ["compute_pipeline", "java_ssi_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: dotnet_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

python_ssi_pipeline:
  stage: python
  needs: ["compute_pipeline", "dotnet_ssi_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: python_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

php_ssi_pipeline:
  stage: php
  needs: ["compute_pipeline", "python_ssi_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: php_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

ruby_ssi_pipeline:
  stage: ruby
  needs: ["compute_pipeline", "php_ssi_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: ruby_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

check_pipeline_status:
  stage: pipeline-status
  image: registry.ddbuild.io/ci/libdatadog-build/ci_docker_base:67145216
  tags: ["runner:docker"]
  script:
    - set -e
    - echo "üîç Checking pipeline status for parent and child pipelines..."

    # Retrieve and validate GitLab token
    - |
      echo "üîê Retrieving GitLab token from AWS SSM..."
      if ! export GITLAB_TOKEN=$(aws ssm get-parameter --region us-east-1 --name "ci.$CI_PROJECT_NAME.gitlab.token" --with-decryption --query "Parameter.Value" --out text 2>/dev/null); then
        echo "‚ùå ERROR: Failed to retrieve GitLab token from AWS SSM"
        echo "   Check if the parameter 'ci.$CI_PROJECT_NAME.gitlab.token' exists in us-east-1"
        exit 1
      fi
      GITLAB_TOKEN="${GITLAB_TOKEN}rmm"

      if [ -z "$GITLAB_TOKEN" ] || [ "$GITLAB_TOKEN" = "None" ]; then
        echo "‚ùå ERROR: GitLab token is empty or invalid"
        exit 1
      fi
      echo "‚úÖ GitLab token retrieved successfully"

    # Enhanced API call function with error handling
    - |
      gitlab_api_call() {
        local url="$1"
        local response
        local http_code
        local temp_file="/tmp/gitlab_response_$$"

        echo "üåê Making API call to: $url"

        # Use curl with write-out to capture both response and HTTP status code
        http_code=$(curl --silent --write-out "%{http_code}" --header "PRIVATE-TOKEN: $GITLAB_TOKEN" --output "$temp_file" "$url" 2>/dev/null)
        response=$(cat "$temp_file" 2>/dev/null || echo "")
        rm -f "$temp_file"

        echo "üì° HTTP Status Code: $http_code"

        # Check HTTP status code
        if [ "$http_code" != "200" ]; then
          echo "‚ùå ERROR: GitLab API call failed with HTTP $http_code"
          echo "   URL: $url"
          echo "   Response: $response"

          case "$http_code" in
            "401")
              echo "   üîë HTTP 401 Unauthorized - GitLab token is expired or invalid"
              echo "   üí° Check if your GitLab token needs to be renewed"
              ;;
            "403")
              echo "   üö´ HTTP 403 Forbidden - GitLab token lacks necessary permissions"
              echo "   üí° Token needs api, read_api, or read_repository scope"
              ;;
            "404")
              echo "   üîç HTTP 404 Not Found - Resource does not exist"
              echo "   üí° Check if the project ID or pipeline ID is correct"
              ;;
            "429")
              echo "   ‚è∞ HTTP 429 Too Many Requests - Rate limit exceeded"
              echo "   üí° Wait a moment and try again"
              ;;
            "500"|"502"|"503"|"504")
              echo "   üîß HTTP $http_code Server Error - GitLab API is experiencing issues"
              echo "   üí° This is likely a temporary GitLab service issue"
              ;;
            "000")
              echo "   üåê HTTP 000 Network Error - Cannot connect to GitLab"
              echo "   üí° Check network connectivity or GitLab service status"
              ;;
            *)
              echo "   ‚ùì HTTP $http_code Unknown Error"
              echo "   üí° Check GitLab API documentation for this status code"
              ;;
          esac
          return 1
        fi

        # Validate JSON response
        if ! echo "$response" | jq -e type > /dev/null 2>&1; then
          echo "‚ùå ERROR: Invalid JSON response from GitLab API"
          echo "   HTTP Status: $http_code"
          echo "   Response: $response"
          return 1
        fi

        echo "$response"
      }

    # Consolidated function to count failed jobs with pagination
    - |
      count_failed_jobs() {
        local base_url="$1"
        local failed_count=0
        local page=1

        while true; do
          echo "   üìÑ Fetching page $page..."

          # Call API and capture response - error messages will be displayed by gitlab_api_call
          local response temp_response_file="/tmp/count_jobs_$$"
          gitlab_api_call "${base_url}&page=$page&per_page=100" > "$temp_response_file"
          local api_exit_code=$?

          if [ $api_exit_code -ne 0 ]; then
            echo "‚ùå API call failed for page $page"
            rm -f "$temp_response_file"
            return 1
          fi

          response=$(cat "$temp_response_file")
          rm -f "$temp_response_file"

          local page_failed_jobs jobs_count
          page_failed_jobs=$(echo "$response" | jq '[.[] | select(.status == "failed")] | length')
          jobs_count=$(echo "$response" | jq 'length')

          echo "   üìä Page $page: $jobs_count jobs total, $page_failed_jobs failed"
          failed_count=$((failed_count + page_failed_jobs))

          # Break if we got less than 100 results (last page)
          [ "$jobs_count" -lt 100 ] && break
          ((page++))
        done

        echo "$failed_count"
      }

    # Check parent pipeline
    - |
      echo "üìã Checking parent pipeline jobs..."
      if ! FAILED_JOBS=$(count_failed_jobs "$CI_API_V4_URL/projects/$CI_PROJECT_ID/pipelines/$CI_PIPELINE_ID/jobs?"); then
        echo "‚ùå Failed to check parent pipeline jobs"
        exit 1
      fi
      echo "   Parent pipeline failed jobs: $FAILED_JOBS"

    # Check child pipelines
    - |
      echo "üîó Checking child pipeline jobs..."
      if ! CHILD_PIPELINES=$(gitlab_api_call "$CI_API_V4_URL/projects/$CI_PROJECT_ID/pipelines/$CI_PIPELINE_ID/bridges"); then
        echo "‚ùå Failed to retrieve child pipelines"
        exit 1
      fi

      FAILED_CHILD_JOBS=0
      CHILD_PIPELINE_IDS=$(echo "$CHILD_PIPELINES" | jq -r '.[].downstream_pipeline.id // empty')

      if [ -n "$CHILD_PIPELINE_IDS" ]; then
        for CHILD_PIPELINE in $CHILD_PIPELINE_IDS; do
          echo "   Checking child pipeline: $CHILD_PIPELINE"
          if ! CHILD_FAILED=$(count_failed_jobs "$CI_API_V4_URL/projects/$CI_PROJECT_ID/pipelines/$CHILD_PIPELINE/jobs?"); then
            echo "‚ùå Failed to check child pipeline $CHILD_PIPELINE"
            exit 1
          fi
          FAILED_CHILD_JOBS=$((FAILED_CHILD_JOBS + CHILD_FAILED))
        done
      else
        echo "   No child pipelines found"
      fi
      echo "   Child pipelines failed jobs: $FAILED_CHILD_JOBS"

    # Final status check
    - |
      TOTAL_FAILED=$((FAILED_JOBS + FAILED_CHILD_JOBS))
      echo "üìä Pipeline Status Summary:"
      echo "   Parent failed jobs: $FAILED_JOBS"
      echo "   Child failed jobs: $FAILED_CHILD_JOBS"
      echo "   Total failed jobs: $TOTAL_FAILED"

      if [ "$TOTAL_FAILED" -gt 0 ]; then
        echo "‚ùå Pipeline failed: $TOTAL_FAILED job(s) did not succeed"
        exit 1
      fi

      echo "‚úÖ All jobs and child pipelines passed!"
  when: always
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

delete_amis:
  extends: .base_job_onboarding
  stage: system-tests-utils
  allow_failure: false
  variables:
    AMI_RETENTION_DAYS: 10
    AMI_LAST_LAUNCHED_DAYS: 10
  script:
        - ./build.sh -i runner
        - source venv/bin/activate
        - python utils/scripts/pulumi_clean_up.py --component amis --ami-retention-days $AMI_RETENTION_DAYS --ami-last-launched-days $AMI_LAST_LAUNCHED_DAYS
  rules:
    - if: '$SCHEDULED_JOB == "delete_amis"'
  after_script: echo "Finish"
  timeout: 3h

delete_amis_by_name_or_lang:
  extends: .base_job_onboarding
  stage: system-tests-utils
  allow_failure: false
  script:
        - |
          if [ -z "$AMI_NAME" ] && [ -z "$AMI_LANG" ]; then
            echo "‚ùå ERROR: Either AMI_NAME or AMI_LANG must be set."
            exit 1
          fi
          echo "‚úÖ Proceeding with AMI_NAME=$AMI_NAME, AMI_LANG=$AMI_LANG"
        - ./build.sh -i runner
        - source venv/bin/activate
        - |
          CMD="python utils/scripts/pulumi_clean_up.py --component amis_by_name"

          if [ -n "$AMI_NAME" ]; then
            CMD="$CMD --ami-name $AMI_NAME"
          fi

          if [ -n "$AMI_LANG" ]; then
            CMD="$CMD --ami-lang $AMI_LANG"
          fi

          echo "Running: $CMD"
          eval $CMD
  rules:
    - if: '$SCHEDULED_JOB == "delete_amis_by_name_or_lang"'
  after_script: echo "Finish"

delete_ec2_instances:
  extends: .base_job_onboarding
  stage: system-tests-utils
  allow_failure: false
  variables:
    EC2_AGE_MINUTES: 45
  script:
        - ./build.sh -i runner
        - source venv/bin/activate
        - python utils/scripts/pulumi_clean_up.py --component ec2 --ec2-age-minutes $EC2_AGE_MINUTES
  rules:
    - if: '$SCHEDULED_JOB == "delete_ec2_instances"'
  after_script: echo "Finish"

count_amis:
  extends: .base_job_onboarding
  stage: system-tests-utils
  allow_failure: false
  script:
        - ./build.sh -i runner
        - source venv/bin/activate
        - python utils/scripts/pulumi_clean_up.py --component amis_count
  rules:
    - if: '$SCHEDULED_JOB == "count_amis"'
  after_script: echo "Finish"

check_merge_labels:
  #Build docker images if it's needed. Check if the PR has the labels associated with the image build.
  image: registry.ddbuild.io/ci/libdatadog-build/ci_docker_base:67145216
  tags: ["runner:docker"]

  stage: system-tests-utils
  allow_failure: true
  before_script:
    - export GH_TOKEN=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.gh-token --with-decryption --query "Parameter.Value" --out text)
    - export DOCKER_LOGIN=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.docker-login-write --with-decryption --query "Parameter.Value" --out text)
    - export DOCKER_LOGIN_PASS=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.docker-login-pass-write --with-decryption --query "Parameter.Value" --out text)
  script:
    -  echo $GH_TOKEN | docker login ghcr.io -u publisher --password-stdin
    - ./utils/scripts/get_pr_merged_labels.sh
  rules:
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "main"

generate_system_tests_end_to_end_images:
  image: registry.ddbuild.io/ci/libdatadog-build/ci_docker_base:67145216
  tags: ["runner:docker"]
  needs: []
  stage: system-tests-utils
  allow_failure: true
  before_script:
    - export DOCKER_LOGIN=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.docker-login-write --with-decryption --query "Parameter.Value" --out text)
    - export DOCKER_LOGIN_PASS=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.docker-login-pass-write --with-decryption --query "Parameter.Value" --out text)
  script:
      - ./utils/build/build_tracer_buddies.sh --push
      - ./utils/build/build_python_base_images.sh --push
  when: manual

generate_system_tests_lib_injection_images:
  extends: .base_job_k8s_docker_ssi
  needs: []
  stage: system-tests-utils
  allow_failure: true
  variables:
    PRIVATE_DOCKER_REGISTRY: 235494822917.dkr.ecr.us-east-1.amazonaws.com
    PRIVATE_DOCKER_REGISTRY_USER: AWS
  script:
      - aws ecr get-login-password | docker login --username ${PRIVATE_DOCKER_REGISTRY_USER} --password-stdin ${PRIVATE_DOCKER_REGISTRY}
      - ./lib-injection/build/build_lib_injection_images.sh $PRIVATE_DOCKER_REGISTRY
  when: manual

.delayed_base_job:
    image: registry.ddbuild.io/ci/libdatadog-build/ci_docker_base:67145216
    tags: ["arch:amd64"]
    script:
        - echo "‚è≥ Waiting before triggering the child pipeline..."
    when: delayed
    start_in: 5 minutes