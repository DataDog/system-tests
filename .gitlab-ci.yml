include:
  - remote: https://gitlab-templates.ddbuild.io/libdatadog/include/single-step-instrumentation-tests.yml
stages:
  - configure
  - nodejs
  - java
  - dotnet
  - python
  - php
  - ruby
  - pipeline-status
  - system-tests-utils

variables:
    # Do not modify this - must be the repository name for Kubernetes gitlab runners to run
    KUBERNETES_SERVICE_ACCOUNT_OVERWRITE: system-tests #helm-charts
    TEST: 1

compute_pipeline:
  image: registry.ddbuild.io/ci/libdatadog-build/system-tests:57161036
  tags: ["arch:amd64"]
  stage: configure
  variables:
    CI_ENVIRONMENT: "prod"
  script:
    - |
      if [ -z "$SYSTEM_TESTS_SCENARIOS" ] && [ -z "$SYSTEM_TESTS_SCENARIOS_GROUPS" ]; then
        echo "❌ Both SYSTEM_TESTS_SCENARIOS and SYSTEM_TESTS_SCENARIOS_GROUPS are not defined.Computing changes..."
        ./build.sh -i runner
        source venv/bin/activate
        ./run.sh MOCK_THE_TEST --collect-only --scenario-report
        git clone https://github.com/DataDog/system-tests.git original
        git fetch --all  # Ensure all branches are available
        git branch --track $CI_COMMIT_REF_NAME origin/$CI_COMMIT_REF_NAME || true  # Track branch if not tracked
        git checkout $CI_COMMIT_REF_NAME  # Ensure the branch is checked out
        BASE_COMMIT=$(git merge-base origin/main $CI_COMMIT_REF_NAME)  # Get the base commit
        echo "Branch was created from commit--> $BASE_COMMIT"
        git diff --name-only $BASE_COMMIT $CI_COMMIT_SHA  >> modified_files.txt # List modified files
        cat modified_files.txt
        python utils/scripts/compute_impacted_scenario.py >> impacted_scenarios.txt
        cat impacted_scenarios.txt
        source impacted_scenarios.txt
      else
          echo "✅ SYSTEM_TESTS_SCENARIOS OR SYSTEM_TESTS_SCENARIOS_GROUPS are set."
          export scenarios=$SYSTEM_TESTS_SCENARIOS
          export scenarios_groups=$SYSTEM_TESTS_SCENARIOS_GROUPS
          cd /system-tests
          git pull # update to most recent system-tests
          ./build.sh -i runner
          source venv/bin/activate
      fi
    - python utils/scripts/compute-workflow-parameters.py nodejs -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - python utils/scripts/compute-workflow-parameters.py java -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - python utils/scripts/compute-workflow-parameters.py dotnet -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - python utils/scripts/compute-workflow-parameters.py python -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - python utils/scripts/compute-workflow-parameters.py php -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - python utils/scripts/compute-workflow-parameters.py ruby -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - |
      if [ -n "$SYSTEM_TESTS_SCENARIOS" ] || [ -n "$SYSTEM_TESTS_SCENARIOS_GROUPS" ]; then
        cp *.yml "$CI_PROJECT_DIR"
      fi
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'
  artifacts:
    paths:
      - nodejs_ssi_gitlab_pipeline.yml
      - java_ssi_gitlab_pipeline.yml
      - dotnet_ssi_gitlab_pipeline.yml
      - python_ssi_gitlab_pipeline.yml
      - php_ssi_gitlab_pipeline.yml
      - ruby_ssi_gitlab_pipeline.yml

nodejs_ssi_pipeline:
  stage: nodejs
  needs: ["compute_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: nodejs_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

java_ssi_pipeline:
  stage: java
  needs: ["compute_pipeline", "nodejs_ssi_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: java_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

dotnet_ssi_pipeline:
  stage: dotnet
  needs: ["compute_pipeline", "java_ssi_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: dotnet_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

python_ssi_pipeline:
  stage: python
  needs: ["compute_pipeline", "dotnet_ssi_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: python_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

php_ssi_pipeline:
  stage: php
  needs: ["compute_pipeline", "python_ssi_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: php_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

ruby_ssi_pipeline:
  stage: ruby
  needs: ["compute_pipeline", "php_ssi_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: ruby_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

check_pipeline_status:
  stage: pipeline-status
  image: registry.ddbuild.io/images/ci_docker_base
  tags: ["runner:docker"]
  script:
    - echo "Checking for failed jobs in parent and child pipelines..."
    - export GITLAB_TOKEN=$(aws ssm get-parameter --region us-east-1 --name "ci.$CI_PROJECT_NAME.gitlab.token" --with-decryption --query "Parameter.Value" --out text)
    - |
      RESPONSE=$(curl --silent --header "PRIVATE-TOKEN: $GITLAB_TOKEN" \
      "$CI_API_V4_URL/projects/$CI_PROJECT_ID/pipelines/$CI_PIPELINE_ID/jobs")

      # Validate JSON response
      if ! echo "$RESPONSE" | jq -e type > /dev/null 2>&1; then
        echo "❌ Error: Invalid JSON response from GitLab API."
        exit 1
      fi

      FAILED_JOBS=$(echo "$RESPONSE" | jq '[.[] | select(.status == "failed")] | length')

      # Fetch child pipelines
      CHILD_PIPELINES=$(curl --silent --header "PRIVATE-TOKEN: $GITLAB_TOKEN" \
      "$CI_API_V4_URL/projects/$CI_PROJECT_ID/pipelines/$CI_PIPELINE_ID/bridges" | jq -r '.[].downstream_pipeline.id')

      FAILED_CHILD_JOBS=0
      for CHILD_PIPELINE in $CHILD_PIPELINES; do
        CHILD_FAILED_JOBS=$(curl --silent --header "PRIVATE-TOKEN: $GITLAB_TOKEN" \
        "$CI_API_V4_URL/projects/$CI_PROJECT_ID/pipelines/$CHILD_PIPELINE/jobs" | jq '[.[] | select(.status == "failed")] | length')

        FAILED_CHILD_JOBS=$((FAILED_CHILD_JOBS + CHILD_FAILED_JOBS))
      done

      TOTAL_FAILED=$((FAILED_JOBS + FAILED_CHILD_JOBS))

      if [ "$TOTAL_FAILED" -gt 0 ]; then
        echo "❌ Pipeline failed: $TOTAL_FAILED job(s) did not succeed."
        exit 1
      fi

    - echo "✅ All jobs and child pipelines passed!"
  when: always
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

delete_amis:
  extends: .base_job_onboarding
  stage: system-tests-utils
  allow_failure: false
  script:
        - ./build.sh -i runner
        - source venv/bin/activate
        - python utils/scripts/pulumi_clean_up.py --component amis --ami-retention-days 0 --ami-last-launched-days 0
  rules:
    - if: '$SCHEDULED_JOB == "delete_amis"'
  after_script: echo "Finish"
  timeout: 3h

check_merge_labels:
  #Build docker images if it's needed. Check if the PR has the labels associated with the image build.
  image: registry.ddbuild.io/images/ci_docker_base
  tags: ["runner:docker"]

  stage: system-tests-utils
  allow_failure: true
  before_script:
    - export GH_TOKEN=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.gh-token --with-decryption --query "Parameter.Value" --out text)
    - export DOCKER_LOGIN=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.docker-login-write --with-decryption --query "Parameter.Value" --out text)
    - export DOCKER_LOGIN_PASS=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.docker-login-pass-write --with-decryption --query "Parameter.Value" --out text)
  script:
    -  echo $GH_TOKEN | docker login ghcr.io -u publisher --password-stdin
    - ./utils/scripts/get_pr_merged_labels.sh
  rules:
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "main"

generate_system_tests_images:
  image: registry.ddbuild.io/images/ci_docker_base
  tags: ["runner:docker"]

  stage: system-tests-utils
  allow_failure: true
  before_script:
    - export GH_TOKEN=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.gh-token --with-decryption --query "Parameter.Value" --out text)
    - export DOCKER_LOGIN=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.docker-login-write --with-decryption --query "Parameter.Value" --out text)
    - export DOCKER_LOGIN_PASS=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.docker-login-pass-write --with-decryption --query "Parameter.Value" --out text)
  script:
      -  echo $GH_TOKEN | docker login ghcr.io -u publisher --password-stdin
      - ./utils/build/build_tracer_buddies.sh --push
      - ./utils/build/build_python_base_images.sh --push
      - ./lib-injection/build/build_lib_injection_images.sh
  when: manual

.delayed_base_job:
    image: registry.ddbuild.io/images/ci_docker_base
    tags: ["arch:amd64"]
    script:
        - echo "⏳ Waiting before triggering the child pipeline..."
    when: delayed
    start_in: 5 minutes