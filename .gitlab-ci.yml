include:
  - remote: https://gitlab-templates.ddbuild.io/libdatadog/one-pipeline/ca/2fc0ca684c4322af76c172905af32c6c583303dcecb07dba05bac5f85b7606ae/single-step-instrumentation-tests.yml

stages:
  - configure
  - nodejs
  - java
  - dotnet
  - python
  - php
  - ruby
  - pipeline-status
  - system-tests-utils

variables:
    # Do not modify this - must be the repository name for Kubernetes gitlab runners to run
    KUBERNETES_SERVICE_ACCOUNT_OVERWRITE: system-tests #helm-charts
    TEST: 1

compute_pipeline:
  image: registry.ddbuild.io/ci/libdatadog-build/system-tests:57161036
  tags: ["arch:amd64"]
  stage: configure
  variables:
    CI_ENVIRONMENT: "prod"
  script:
    - |
      if [ -z "$SYSTEM_TESTS_SCENARIOS" ] && [ -z "$SYSTEM_TESTS_SCENARIOS_GROUPS" ]; then
        echo "‚ùå Both SYSTEM_TESTS_SCENARIOS and SYSTEM_TESTS_SCENARIOS_GROUPS are not defined.Computing changes..."
        ./build.sh -i runner
        source venv/bin/activate
        ./run.sh MOCK_THE_TEST --collect-only --scenario-report
        git clone https://github.com/DataDog/system-tests.git original
        git fetch --all  # Ensure all branches are available
        git branch --track $CI_COMMIT_REF_NAME origin/$CI_COMMIT_REF_NAME || true  # Track branch if not tracked
        git checkout $CI_COMMIT_REF_NAME  # Ensure the branch is checked out
        BASE_COMMIT=$(git merge-base origin/main $CI_COMMIT_REF_NAME)  # Get the base commit
        echo "Branch was created from commit--> $BASE_COMMIT"
        git diff --name-only $BASE_COMMIT $CI_COMMIT_SHA  >> modified_files.txt # List modified files
        cat modified_files.txt
        python utils/scripts/compute_impacted_scenario.py >> impacted_scenarios.txt
        cat impacted_scenarios.txt
        source impacted_scenarios.txt
      else
          echo "‚úÖ SYSTEM_TESTS_SCENARIOS OR SYSTEM_TESTS_SCENARIOS_GROUPS are set."
          export scenarios=$SYSTEM_TESTS_SCENARIOS
          export scenarios_groups=$SYSTEM_TESTS_SCENARIOS_GROUPS
          cd /system-tests
          git pull
          if [ -n "$SYSTEM_TESTS_REF" ]; then
            git checkout $SYSTEM_TESTS_REF
          else
            echo "‚ö†Ô∏è  SYSTEM_TESTS_REF variable is not set, skipping git checkout"
          fi
          ./build.sh -i runner
          source venv/bin/activate
      fi
    - python utils/scripts/compute-workflow-parameters.py nodejs -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - python utils/scripts/compute-workflow-parameters.py java -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - python utils/scripts/compute-workflow-parameters.py dotnet -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - python utils/scripts/compute-workflow-parameters.py python -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - python utils/scripts/compute-workflow-parameters.py php -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - python utils/scripts/compute-workflow-parameters.py ruby -s "$scenarios" -g "$scenarios_groups" --parametric-job-count 1 --ci-environment "${CI_ENVIRONMENT}" --format gitlab
    - |
      if [ -n "$SYSTEM_TESTS_SCENARIOS" ] || [ -n "$SYSTEM_TESTS_SCENARIOS_GROUPS" ]; then
        cp *.yml "$CI_PROJECT_DIR"
      fi
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'
  artifacts:
    paths:
      - nodejs_ssi_gitlab_pipeline.yml
      - java_ssi_gitlab_pipeline.yml
      - dotnet_ssi_gitlab_pipeline.yml
      - python_ssi_gitlab_pipeline.yml
      - php_ssi_gitlab_pipeline.yml
      - ruby_ssi_gitlab_pipeline.yml

nodejs_ssi_pipeline:
  stage: nodejs
  needs: ["compute_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: nodejs_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

java_ssi_pipeline:
  stage: java
  needs: ["compute_pipeline", "nodejs_ssi_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: java_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

dotnet_ssi_pipeline:
  stage: dotnet
  needs: ["compute_pipeline", "java_ssi_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: dotnet_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

python_ssi_pipeline:
  stage: python
  needs: ["compute_pipeline", "dotnet_ssi_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: python_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

php_ssi_pipeline:
  stage: php
  needs: ["compute_pipeline", "python_ssi_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: php_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

ruby_ssi_pipeline:
  stage: ruby
  needs: ["compute_pipeline", "php_ssi_pipeline"]
  allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: ruby_ssi_gitlab_pipeline.yml
        job: compute_pipeline
    strategy: depend
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

check_pipeline_status:
  stage: pipeline-status
  image: registry.ddbuild.io/ci/libdatadog-build/ci_docker_base:67145216
  tags: ["runner:docker"]
  script:
    - set -e
    - echo "üîç Checking pipeline status for parent and child pipelines..."

    # Retrieve and validate GitLab token
    - |
      echo "üîê Getting GitLab token..."
      GITLAB_TOKEN=$(aws ssm get-parameter --region us-east-1 --name "ci.$CI_PROJECT_NAME.gitlab.token" --with-decryption --query "Parameter.Value" --out text 2>/dev/null) || { echo "‚ùå Failed to get token from SSM"; exit 1; }
      [ -z "$GITLAB_TOKEN" ] || [ "$GITLAB_TOKEN" = "None" ] && { echo "‚ùå Token is empty/invalid"; exit 1; }
      echo "‚úÖ Token retrieved"

            # Enhanced API call function with error handling
    - |
      gitlab_api_call() {
        local url="$1" temp_file="/tmp/gitlab_response_$$"
        
        echo "üåê API call: $url" >&2
        local http_code=$(curl --silent --write-out "%{http_code}" --header "PRIVATE-TOKEN: $GITLAB_TOKEN" --output "$temp_file" "$url" 2>/dev/null)
        local response=$(cat "$temp_file" 2>/dev/null || echo "")
        rm -f "$temp_file"
        
        echo "üì° HTTP $http_code" >&2
        
        if [ "$http_code" != "200" ]; then
          echo "‚ùå API failed: HTTP $http_code" >&2
          [ -n "$response" ] && echo "   Response: $response" >&2
          
          case "$http_code" in
            "401") echo "   üîë Token expired/invalid - renew GitLab token" >&2 ;;
            "403") echo "   üö´ Insufficient permissions - check token scope" >&2 ;;
            "404") echo "   üîç Resource not found - check project/pipeline ID" >&2 ;;
            "429") echo "   ‚è∞ Rate limited - wait and retry" >&2 ;;
            "5"*) echo "   üîß GitLab server error - temporary issue" >&2 ;;
            "000") echo "   üåê Network error - check connectivity" >&2 ;;
          esac
          return 1
        fi
        
        if ! echo "$response" | jq -e type >/dev/null 2>&1; then
          echo "‚ùå Invalid JSON response" >&2
          return 1
        fi
        
        echo "$response"
      }

            # Function to count failed jobs with pagination
    - |
      count_failed_jobs() {
        local base_url="$1" failed_count=0 page=1
        
        while true; do
          echo "   üìÑ Page $page..." >&2
          
          set +e
          local response=$(gitlab_api_call "${base_url}&page=$page&per_page=100")
          local exit_code=$?
          set -e
          
          [ $exit_code -ne 0 ] && return 1
          
          local page_failed=$(echo "$response" | jq '[.[] | select(.status == "failed")] | length')
          local jobs_count=$(echo "$response" | jq 'length')
          
          echo "   üìä Page $page: $jobs_count total, $page_failed failed" >&2
          failed_count=$((failed_count + page_failed))
          
          [ "$jobs_count" -lt 100 ] && break
          ((page++))
        done
        
        echo "$failed_count"
      }

            # Check parent and child pipelines
    - |
      echo "üìã Checking parent pipeline..."
      set +e; FAILED_JOBS=$(count_failed_jobs "$CI_API_V4_URL/projects/$CI_PROJECT_ID/pipelines/$CI_PIPELINE_ID/jobs?"); set -e
      [ $? -ne 0 ] && { echo "‚ùå Failed to check parent pipeline"; exit 1; }
      
      echo "üîó Checking child pipelines..."
      set +e; CHILD_PIPELINES=$(gitlab_api_call "$CI_API_V4_URL/projects/$CI_PROJECT_ID/pipelines/$CI_PIPELINE_ID/bridges"); set -e
      [ $? -ne 0 ] && { echo "‚ùå Failed to get child pipelines"; exit 1; }
      
      FAILED_CHILD_JOBS=0
      for CHILD_ID in $(echo "$CHILD_PIPELINES" | jq -r '.[].downstream_pipeline.id // empty'); do
        echo "   Child pipeline: $CHILD_ID"
        set +e; CHILD_FAILED=$(count_failed_jobs "$CI_API_V4_URL/projects/$CI_PROJECT_ID/pipelines/$CHILD_ID/jobs?"); set -e
        [ $? -ne 0 ] && { echo "‚ùå Failed to check child $CHILD_ID"; exit 1; }
        FAILED_CHILD_JOBS=$((FAILED_CHILD_JOBS + CHILD_FAILED))
      done

        # Final status check
    - |
      TOTAL_FAILED=$((FAILED_JOBS + FAILED_CHILD_JOBS))
      echo "üìä Summary: $FAILED_JOBS parent + $FAILED_CHILD_JOBS child = $TOTAL_FAILED failed jobs"
      
      if [ "$TOTAL_FAILED" -gt 0 ]; then
        echo "‚ùå Pipeline failed: $TOTAL_FAILED job(s) failed"
        exit 1
      fi
      echo "‚úÖ All pipelines passed!"
  when: always
  rules:
    - if: '$SCHEDULED_JOB == ""'
    - if: '$SCHEDULED_JOB == null'

delete_amis:
  extends: .base_job_onboarding
  stage: system-tests-utils
  allow_failure: false
  variables:
    AMI_RETENTION_DAYS: 10
    AMI_LAST_LAUNCHED_DAYS: 10
  script:
        - ./build.sh -i runner
        - source venv/bin/activate
        - python utils/scripts/pulumi_clean_up.py --component amis --ami-retention-days $AMI_RETENTION_DAYS --ami-last-launched-days $AMI_LAST_LAUNCHED_DAYS
  rules:
    - if: '$SCHEDULED_JOB == "delete_amis"'
  after_script: echo "Finish"
  timeout: 3h

delete_amis_by_name_or_lang:
  extends: .base_job_onboarding
  stage: system-tests-utils
  allow_failure: false
  script:
        - |
          if [ -z "$AMI_NAME" ] && [ -z "$AMI_LANG" ]; then
            echo "‚ùå ERROR: Either AMI_NAME or AMI_LANG must be set."
            exit 1
          fi
          echo "‚úÖ Proceeding with AMI_NAME=$AMI_NAME, AMI_LANG=$AMI_LANG"
        - ./build.sh -i runner
        - source venv/bin/activate
        - |
          CMD="python utils/scripts/pulumi_clean_up.py --component amis_by_name"

          if [ -n "$AMI_NAME" ]; then
            CMD="$CMD --ami-name $AMI_NAME"
          fi

          if [ -n "$AMI_LANG" ]; then
            CMD="$CMD --ami-lang $AMI_LANG"
          fi

          echo "Running: $CMD"
          eval $CMD
  rules:
    - if: '$SCHEDULED_JOB == "delete_amis_by_name_or_lang"'
  after_script: echo "Finish"

delete_ec2_instances:
  extends: .base_job_onboarding
  stage: system-tests-utils
  allow_failure: false
  variables:
    EC2_AGE_MINUTES: 45
  script:
        - ./build.sh -i runner
        - source venv/bin/activate
        - python utils/scripts/pulumi_clean_up.py --component ec2 --ec2-age-minutes $EC2_AGE_MINUTES
  rules:
    - if: '$SCHEDULED_JOB == "delete_ec2_instances"'
  after_script: echo "Finish"

count_amis:
  extends: .base_job_onboarding
  stage: system-tests-utils
  allow_failure: false
  script:
        - ./build.sh -i runner
        - source venv/bin/activate
        - python utils/scripts/pulumi_clean_up.py --component amis_count
  rules:
    - if: '$SCHEDULED_JOB == "count_amis"'
  after_script: echo "Finish"

check_merge_labels:
  #Build docker images if it's needed. Check if the PR has the labels associated with the image build.
  image: registry.ddbuild.io/ci/libdatadog-build/ci_docker_base:67145216
  tags: ["runner:docker"]

  stage: system-tests-utils
  allow_failure: true
  before_script:
    - export GH_TOKEN=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.gh-token --with-decryption --query "Parameter.Value" --out text)
    - export DOCKER_LOGIN=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.docker-login-write --with-decryption --query "Parameter.Value" --out text)
    - export DOCKER_LOGIN_PASS=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.docker-login-pass-write --with-decryption --query "Parameter.Value" --out text)
  script:
    -  echo $GH_TOKEN | docker login ghcr.io -u publisher --password-stdin
    - ./utils/scripts/get_pr_merged_labels.sh
  rules:
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "main"

generate_system_tests_end_to_end_images:
  image: registry.ddbuild.io/ci/libdatadog-build/ci_docker_base:67145216
  tags: ["runner:docker"]
  needs: []
  stage: system-tests-utils
  allow_failure: true
  before_script:
    - export DOCKER_LOGIN=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.docker-login-write --with-decryption --query "Parameter.Value" --out text)
    - export DOCKER_LOGIN_PASS=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.docker-login-pass-write --with-decryption --query "Parameter.Value" --out text)
  script:
      - ./utils/build/build_tracer_buddies.sh --push
      - ./utils/build/build_python_base_images.sh --push
  when: manual

generate_system_tests_lib_injection_images:
  extends: .base_job_k8s_docker_ssi
  needs: []
  stage: system-tests-utils
  allow_failure: true
  variables:
    PRIVATE_DOCKER_REGISTRY: 235494822917.dkr.ecr.us-east-1.amazonaws.com
    PRIVATE_DOCKER_REGISTRY_USER: AWS
  script:
      - aws ecr get-login-password | docker login --username ${PRIVATE_DOCKER_REGISTRY_USER} --password-stdin ${PRIVATE_DOCKER_REGISTRY}
      - ./lib-injection/build/build_lib_injection_images.sh $PRIVATE_DOCKER_REGISTRY
  when: manual

.delayed_base_job:
    image: registry.ddbuild.io/ci/libdatadog-build/ci_docker_base:67145216
    tags: ["arch:amd64"]
    script:
        - echo "‚è≥ Waiting before triggering the child pipeline..."
    when: delayed
    start_in: 5 minutes