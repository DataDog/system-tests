include:
  - remote: https://gitlab-templates.ddbuild.io/libdatadog/include/single-step-instrumentation-tests.yml
stages:
  - docker_ssi_pipelines
  - aws_ssi_pipelines
  #- nodejs_tracer
  #- java_tracer
  #- python_tracer
  #- dotnet_tracer
  #- php_tracer
  - stats_results
  - parse_results
  - before_tests

variables:
    # Do not modify this - must be the repository name for Kubernetes gitlab runners to run
    KUBERNETES_SERVICE_ACCOUNT_OVERWRITE: system-tests #helm-charts
    TEST: 1
    AMI_UPDATE:
      description: "Set to true to force the update the AMIs used in the system-tests"
    ONBOARDING_FILTER_ENV: "prod"
    ONLY_TEST_LIBRARY: ""
    DD_INSTALLER_LIBRARY_VERSION:
      description: "Set the version of the library to be installed. Use the pipeline id pipeline-${CI_PIPELINE_ID}"
    DD_INSTALLER_INJECTOR_VERSION:
      description: "Set the version of the injector to be installed. Use the pipeline id pipeline-${CI_PIPELINE_ID}"

.base_compute_aws_scenarios:
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/test-infra-definitions/runner:6dd143866d67
  tags: ["arch:amd64"]
  before_script:
    - export DD_API_KEY_ONBOARDING=xyz
    - export DD_APP_KEY_ONBOARDING=xyz

.compute_aws_scenarios:
  #extends: .base_job_onboarding
  extends: .base_compute_aws_scenarios
  stage: aws_ssi_pipelines
  allow_failure: true
  variables:
    TEST_LIBRARY: "nodejs"
    ONBOARDING_FILTER_WEBLOG: "test-app-nodejs"
    SCENARIO: "HOST_AUTO_INJECTION_INSTALL_SCRIPT"
  script:
      - ./build.sh -i runner
      - ./run.sh $SCENARIO --vm-weblog ${ONBOARDING_FILTER_WEBLOG} --vm-env ${ONBOARDING_FILTER_ENV} --vm-library ${TEST_LIBRARY} --vm-provider aws --vm-default-vms All --vm-gitlab-pipeline
  after_script:
    - SCENARIO_SUFIX=$(echo "$SCENARIO" | tr '[:upper:]' '[:lower:]')
    - mkdir -p reports/logs_"${SCENARIO_SUFIX}"
    - cp -R logs_"${SCENARIO_SUFIX}"/gitlab_pipeline.yml reports/logs_"${SCENARIO_SUFIX}"/
  artifacts:
    paths:
      - reports/

.merge_aws_ssi_pipeline:
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/test-infra-definitions/runner:a58cc31c
  stage: aws_ssi_pipelines
  tags: ["arch:amd64"]
  script:
      - |
        for folder in reports/logs*/ ; do
          echo "Checking folder:: ${folder}"
          for filename in ./${folder}gitlab_pipeline.yml; do
            if [ -e ${filename} ]
            then
              echo "Processing pipeline: ${filename}"
              python utils/scripts/merge_gitlab_aws_pipelines.py --input ${filename} --output aws_gitlab_pipeline.yml
            fi
          done
        done
  needs: ["onboarding_nodejs"]
  dependencies:
    - onboarding_nodejs
  artifacts:
    paths:
      - aws_gitlab_pipeline.yml

.exec_aws_ssi_pipeline:
  stage: aws_ssi_pipelines
  needs: ["merge_aws_ssi_pipeline"]
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: always
    - when: manual
      allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: aws_gitlab_pipeline.yml
        job: merge_aws_ssi_pipeline
    strategy: depend

.step1_generate_aws_ssi_pipeline:
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/test-infra-definitions/runner:a58cc31c
  stage: aws_ssi_pipelines
  tags: ["arch:amd64"]
  needs: []
  script:
    - echo ">>>>>>>>>>>>>>> Generating lang pipeline >>>>>>>>>>>>>>>"
    - echo "FILTER_ENV=$ONBOARDING_FILTER_ENV" >> run.env
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: always
    - when: manual
      allow_failure: true
  artifacts:
    reports:
      dotenv: run.env

step1_generate_nodejs_ssi_pipeline:
  extends: .step1_generate_aws_ssi_pipeline
  script:
    - echo ">>>>>>>>>>>>>>> Generating nodejs pipeline >>>>>>>>>>>>>>>"
    - echo "FILTER_ENV=$ONBOARDING_FILTER_ENV" >> run.env

step1_generate_java_ssi_pipeline:
  dependencies: []
  extends: .step1_generate_aws_ssi_pipeline
  script:
    - echo ">>>>>>>>>>>>>>> Generating java pipeline >>>>>>>>>>>>>>>"
    - echo "FILTER_ENV=$ONBOARDING_FILTER_ENV" >> run.env

x_compute_nodejs_scenarios:
  extends: .compute_aws_scenarios
  variables:
    TEST_LIBRARY: "nodejs"
    #Because sometimes I don't want to run all pipeline, I only run step1_xx with env filter param
    ONBOARDING_FILTER_ENV: "$FILTER_ENV"
  parallel:
    matrix:
        - ONBOARDING_FILTER_WEBLOG: [test-app-nodejs]
          SCENARIO:
            - HOST_AUTO_INJECTION_INSTALL_SCRIPT
            - HOST_AUTO_INJECTION_INSTALL_SCRIPT_PROFILING
        - ONBOARDING_FILTER_WEBLOG: [test-app-nodejs-multicontainer]
          SCENARIO:
            - CONTAINER_AUTO_INJECTION_INSTALL_SCRIPT
            - CONTAINER_AUTO_INJECTION_INSTALL_SCRIPT_PROFILING
        - ONBOARDING_FILTER_WEBLOG: [test-app-nodejs,test-app-nodejs-container]
          SCENARIO: [INSTALLER_AUTO_INJECTION,SIMPLE_AUTO_INJECTION_PROFILING]
        - ONBOARDING_FILTER_WEBLOG: [test-app-nodejs-08, test-app-nodejs-16, test-app-nodejs-unsupported-defaults]
          SCENARIO: [INSTALLER_NOT_SUPPORTED_AUTO_INJECTION]
        - ONBOARDING_FILTER_WEBLOG: [test-app-nodejs]
          SCENARIO: [CHAOS_INSTALLER_AUTO_INJECTION]
        - ONBOARDING_FILTER_WEBLOG: [test-app-nodejs-multicontainer,test-app-nodejs-esm]
          SCENARIO: [SIMPLE_INSTALLER_AUTO_INJECTION]
  needs:
    - job: step1_generate_nodejs_ssi_pipeline
      artifacts: true

x_merge_nodejs_ssi_pipeline:
  extends: .merge_aws_ssi_pipeline
  needs: ["x_compute_nodejs_scenarios"]
  dependencies:
    - x_compute_nodejs_scenarios

step2_exec_nodejs_ssi_pipeline:
  extends: .exec_aws_ssi_pipeline
  needs: ["x_merge_nodejs_ssi_pipeline"]
  trigger:
    include:
      - artifact: aws_gitlab_pipeline.yml
        job: x_merge_nodejs_ssi_pipeline
    strategy: depend

check_merge_labels:
  #Build docker images if it's needed. Check if the PR has the labels associated with the image build.
  image: registry.ddbuild.io/images/ci_docker_base
  tags: ["runner:docker"]

  stage: before_tests
  allow_failure: true
  before_script:
    - export GH_TOKEN=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.gh-token --with-decryption --query "Parameter.Value" --out text)
    - export DOCKER_LOGIN=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.docker-login-write --with-decryption --query "Parameter.Value" --out text)
    - export DOCKER_LOGIN_PASS=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.docker-login-pass-write --with-decryption --query "Parameter.Value" --out text)
  script:
    -  echo $GH_TOKEN | docker login ghcr.io -u publisher --password-stdin
    - ./utils/scripts/get_pr_merged_labels.sh
  rules:
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "main"

generate_system_tests_images:
  image: registry.ddbuild.io/images/ci_docker_base
  tags: ["runner:docker"]

  stage: before_tests
  allow_failure: true
  before_script:
    - export GH_TOKEN=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.gh-token --with-decryption --query "Parameter.Value" --out text)
    - export DOCKER_LOGIN=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.docker-login-write --with-decryption --query "Parameter.Value" --out text)
    - export DOCKER_LOGIN_PASS=$(aws ssm get-parameter --region us-east-1 --name ci.system-tests.docker-login-pass-write --with-decryption --query "Parameter.Value" --out text)
  script:
      -  echo $GH_TOKEN | docker login ghcr.io -u publisher --password-stdin
      - ./utils/build/build_tracer_buddies.sh --push
      - ./utils/build/build_python_base_images.sh --push
      - ./lib-injection/build/build_lib_injection_images.sh
  when: manual

step1_generate_docker_ssi_pipeline:
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/test-infra-definitions/runner:a58cc31c
  stage: docker_ssi_pipelines
  tags: ["arch:amd64"]
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: always
    - when: manual
      allow_failure: true
  script:
    - python utils/docker_ssi/docker_ssi_matrix_builder.py --format yaml --output-file ssi_pipeline.yml
  artifacts:
    paths:
      - ssi_pipeline.yml

step2_exec_docker_ssi_pipeline:
  stage: docker_ssi_pipelines
  needs: ["step1_generate_docker_ssi_pipeline"]
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: always
    - when: manual
      allow_failure: true
  variables:
    PARENT_PIPELINE_SOURCE: $CI_PIPELINE_SOURCE
  trigger:
    include:
      - artifact: ssi_pipeline.yml
        job: step1_generate_docker_ssi_pipeline
    strategy: depend
