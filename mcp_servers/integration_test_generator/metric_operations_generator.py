"""Generators for creating metric-specific smoke test operations."""

import json
from pathlib import Path
from typing import Any


def generate_kafka_operation(metric_name: str) -> tuple[list[str], bool]:
    """Generate Kafka-specific operation for a metric.
    
    Returns:
        Tuple of (operations, should_skip)
    """
    operations = []
    skip = False
    
    if metric_name == "kafka.brokers":
        operations = [
            'r = container.exec_run("kafka-broker-api-versions --bootstrap-server localhost:9092")',
            f'logger.info(f"{metric_name}: {{r.output}}")',
        ]
    elif metric_name == "kafka.topic.partitions":
        operations = [
            'r = container.exec_run("kafka-topics --create --topic test-topic --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1")',
            f'logger.info(f"{metric_name}: {{r.output}}")',
        ]
    elif metric_name == "kafka.messages":
        operations = [
            '# Produce messages to generate kafka.messages metric',
            'r = container.exec_run(\'sh -c "echo \\\'message1\\\' | kafka-console-producer --topic test-topic --bootstrap-server localhost:9092"\')',
            'r = container.exec_run(\'sh -c "echo \\\'message2\\\' | kafka-console-producer --topic test-topic --bootstrap-server localhost:9092"\')',
            'r = container.exec_run(\'sh -c "echo \\\'message3\\\' | kafka-console-producer --topic test-topic --bootstrap-server localhost:9092"\')',
            f'logger.info(f"{metric_name}: Generated messages")',
        ]
    elif metric_name in ["kafka.partition.current_offset", "kafka.partition.oldest_offset"]:
        operations = [
            f'# {metric_name} - generated by message production and topic operations',
            'r = container.exec_run("kafka-topics --describe --topic test-topic --bootstrap-server localhost:9092")',
            f'logger.info(f"{metric_name}: {{r.output}}")',
        ]
    elif metric_name in ["kafka.consumer_group.lag", "kafka.consumer_group.lag_sum", 
                         "kafka.consumer_group.members", "kafka.consumer_group.offset",
                         "kafka.consumer_group.offset_sum"]:
        operations = [
            f'# {metric_name} - create consumer group',
            'r = container.exec_run("kafka-console-consumer --topic test-topic --bootstrap-server localhost:9092 --group test-consumer-group --max-messages 2 --from-beginning --timeout-ms 5000")',
            f'logger.info(f"{metric_name}: {{r.output}}")',
        ]
    elif metric_name in ["kafka.partition.replicas", "kafka.partition.replicas_in_sync"]:
        operations = [
            f'# SKIPPED: {metric_name} - requires multiple brokers/replicas in cluster setup',
        ]
        skip = True
    else:
        operations = [
            f'# TODO: Add specific operation for {metric_name}',
        ]
    
    return operations, skip


def generate_redis_operation(metric_name: str) -> tuple[list[str], bool]:
    """Generate Redis-specific operation for a metric.
    
    Returns:
        Tuple of (operations, should_skip)
    """
    operations = []
    skip = False
    
    if "commands" in metric_name or "processed" in metric_name:
        operations = [
            'r = container.exec_run("redis-cli INCR counter")',
            f'logger.info(f"{metric_name}: {{r.output}}")',
        ]
    elif "keys" in metric_name:
        operations = [
            'r = container.exec_run("redis-cli SET key1 value1")',
            'r = container.exec_run("redis-cli SET key2 value2")',
            f'logger.info(f"{metric_name}: {{r.output}}")',
        ]
    elif "net.input" in metric_name or "net.output" in metric_name:
        operations = [
            'r = container.exec_run("redis-cli SET test_key test_value")',
            'r = container.exec_run("redis-cli GET test_key")',
            f'logger.info(f"{metric_name}: {{r.output}}")',
        ]
    elif "memory" in metric_name:
        operations = [
            'r = container.exec_run("redis-cli INFO memory")',
            f'logger.info(f"{metric_name}: {{r.output}}")',
        ]
    elif "replication" in metric_name or "replica" in metric_name or "slaves" in metric_name:
        operations = [
            f'# SKIPPED: {metric_name} - requires replica/slave Redis instance',
        ]
        skip = True
    elif "cluster" in metric_name:
        operations = [
            f'# SKIPPED: {metric_name} - requires Redis cluster setup',
        ]
        skip = True
    elif "sentinel" in metric_name:
        operations = [
            f'# SKIPPED: {metric_name} - requires Redis Sentinel setup',
        ]
        skip = True
    else:
        operations = [
            'r = container.exec_run("redis-cli PING")',
            f'logger.info(f"{metric_name}: {{r.output}}")',
        ]
    
    return operations, skip


def generate_mysql_operation(metric_name: str) -> tuple[list[str], bool]:
    """Generate MySQL-specific operation for a metric.
    
    Returns:
        Tuple of (operations, should_skip)
    """
    operations = []
    skip = False
    
    if "connection" in metric_name or "client" in metric_name:
        operations = [
            'r = container.exec_run("mysql -u root -ppassword -e \'SHOW STATUS LIKE \\\'Threads_connected\\\';\'")',
            f'logger.info(f"{metric_name}: {{r.output}}")',
        ]
    elif "table" in metric_name:
        operations = [
            'r = container.exec_run("mysql -u root -ppassword test_db -e \'CREATE TABLE IF NOT EXISTS test_table (id INT PRIMARY KEY);\'")',
            f'logger.info(f"{metric_name}: {{r.output}}")',
        ]
    elif "operations" in metric_name or "commands" in metric_name:
        operations = [
            'r = container.exec_run("mysql -u root -ppassword test_db -e \'INSERT INTO test_table VALUES (1) ON DUPLICATE KEY UPDATE id=1;\'")',
            'r = container.exec_run("mysql -u root -ppassword test_db -e \'SELECT * FROM test_table;\'")',
            f'logger.info(f"{metric_name}: {{r.output}}")',
        ]
    elif "replica" in metric_name or "replication" in metric_name:
        operations = [
            f'# SKIPPED: {metric_name} - requires MySQL replica setup',
        ]
        skip = True
    elif "deadlock" in metric_name:
        operations = [
            f'# SKIPPED: {metric_name} - requires complex multi-transaction setup',
        ]
        skip = True
    else:
        operations = [
            'r = container.exec_run("mysql -u root -ppassword -e \'SELECT 1;\'")',
            f'logger.info(f"{metric_name}: {{r.output}}")',
        ]
    
    return operations, skip


def generate_postgres_operation(metric_name: str) -> tuple[list[str], bool]:
    """Generate PostgreSQL-specific operation for a metric.
    
    Returns:
        Tuple of (operations, should_skip)
    """
    operations = []
    skip = False
    
    if "table" in metric_name:
        operations = [
            'r = container.exec_run("psql -U system_tests_user -d system_tests_dbname -c \\"CREATE TABLE IF NOT EXISTS test_table (id SERIAL PRIMARY KEY);\\")"',
            f'logger.info(f"{metric_name}: {{r.output}}")',
        ]
    elif "commit" in metric_name or "rollback" in metric_name:
        operations = [
            'r = container.exec_run("psql -U system_tests_user -d system_tests_dbname -c \\"INSERT INTO test_table DEFAULT VALUES;\\")"',
            f'logger.info(f"{metric_name}: {{r.output}}")',
        ]
    elif "connection" in metric_name:
        operations = [
            'r = container.exec_run("psql -U system_tests_user -d system_tests_dbname -c \\"SELECT 1;\\")"',
            f'logger.info(f"{metric_name}: {{r.output}}")',
        ]
    elif "replica" in metric_name or "replication" in metric_name:
        operations = [
            f'# SKIPPED: {metric_name} - requires PostgreSQL replica setup',
        ]
        skip = True
    elif "deadlock" in metric_name:
        operations = [
            f'# SKIPPED: {metric_name} - requires complex multi-transaction setup',
        ]
        skip = True
    else:
        operations = [
            'r = container.exec_run("psql -U system_tests_user -d system_tests_dbname -c \\"SELECT 1;\\")"',
            f'logger.info(f"{metric_name}: {{r.output}}")',
        ]
    
    return operations, skip


def generate_smoke_operations_from_metrics(
    integration_name: str,
    metrics_json_path: Path,
) -> tuple[list[str], list[str]]:
    """Generate smoke test operations by analyzing metrics JSON file.
    
    Args:
        integration_name: Name of the integration (e.g., "kafka", "redis")
        metrics_json_path: Path to the metrics JSON file
    
    Returns:
        Tuple of (all_operations, expected_metrics)
    """
    # Read metrics from JSON
    try:
        with open(metrics_json_path, "r") as f:
            metrics_data = json.load(f)
    except FileNotFoundError:
        # If metrics file doesn't exist yet, return basic operations
        return [
            f'logger.info("Add specific {integration_name} operations here")',
        ], [f"{integration_name}.metric1"]
    
    # Select appropriate generator
    generators = {
        "kafka": generate_kafka_operation,
        "redis": generate_redis_operation,
        "mysql": generate_mysql_operation,
        "postgres": generate_postgres_operation,
        "postgresql": generate_postgres_operation,
    }
    
    generator = generators.get(integration_name.lower())
    if not generator:
        # Fallback for unknown integrations
        return [
            f'logger.info("Add specific {integration_name} operations for each metric")',
        ], list(metrics_data.keys())[:5]
    
    all_operations = []
    expected_metrics = []
    seen_operations = set()  # Deduplicate operations
    
    # Add header comment
    all_operations.append(f'"""Generate activity for each metric in {metrics_json_path.name}"""')
    
    for metric_name in metrics_data.keys():
        operations, should_skip = generator(metric_name)
        
        # Deduplicate operations
        op_key = "\n".join(operations)
        if op_key in seen_operations:
            continue
        seen_operations.add(op_key)
        
        # Add blank line before each metric section
        if all_operations and all_operations[-1] != "":
            all_operations.append("")
        
        all_operations.extend(operations)
        
        # Only add to expected metrics if not skipped
        if not should_skip:
            expected_metrics.append(metric_name)
    
    # If no expected metrics, add a few common ones
    if not expected_metrics and metrics_data:
        expected_metrics = list(metrics_data.keys())[:5]
    
    return all_operations, expected_metrics



